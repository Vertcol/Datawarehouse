{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported sales tables\n",
      "Imported staff tables\n",
      "Imported crm tables\n",
      "Imported inventory table\n",
      "Imported sales product forecast table\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pyodbc\n",
    "\n",
    "select_tables = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "\n",
    "sales_con = sqlite3.connect(\"go_sales.sqlite\")\n",
    "sales_tables = pd.read_sql_query(select_tables, sales_con)\n",
    "\n",
    "sales_country       = pd.read_sql_query(\"SELECT * FROM country;\", sales_con)\n",
    "order_details       = pd.read_sql_query(\"SELECT * FROM order_details;\", sales_con)\n",
    "order_header        = pd.read_sql_query(\"SELECT * FROM order_header;\", sales_con)\n",
    "order_method        = pd.read_sql_query(\"SELECT * FROM order_method;\", sales_con)\n",
    "product             = pd.read_sql_query(\"SELECT * FROM product;\", sales_con)\n",
    "product_line        = pd.read_sql_query(\"SELECT * FROM product_line;\", sales_con)\n",
    "product_type        = pd.read_sql_query(\"SELECT * FROM product_type;\", sales_con)\n",
    "sales_retailer_site = pd.read_sql_query(\"SELECT * FROM retailer_site;\", sales_con)\n",
    "return_reason       = pd.read_sql_query(\"SELECT * FROM return_reason;\", sales_con)\n",
    "returned_item       = pd.read_sql_query(\"SELECT * FROM returned_item;\", sales_con)\n",
    "sales_branch        = pd.read_sql_query(\"SELECT * FROM sales_branch;\", sales_con)\n",
    "sales_staff         = pd.read_sql_query(\"SELECT * FROM sales_staff;\", sales_con)\n",
    "SALES_TARGETData    = pd.read_sql_query(\"SELECT * FROM SALES_TARGETData;\", sales_con)\n",
    "sqlite_sequence     = pd.read_sql_query(\"SELECT * FROM sqlite_sequence;\", sales_con)\n",
    "print(\"Imported sales tables\")\n",
    "\n",
    "staff_con = sqlite3.connect(\"go_staff.sqlite\")\n",
    "staff_tables = pd.read_sql_query(select_tables, staff_con)\n",
    "\n",
    "course            = pd.read_sql_query(\"SELECT * FROM course;\", staff_con)\n",
    "sales_branch      = pd.read_sql_query(\"SELECT * FROM sales_branch;\", staff_con)\n",
    "sales_staff       = pd.read_sql_query(\"SELECT * FROM sales_staff;\", staff_con)\n",
    "satisfaction      = pd.read_sql_query(\"SELECT * FROM satisfaction;\", staff_con)\n",
    "satisfaction_type = pd.read_sql_query(\"SELECT * FROM satisfaction_type;\", staff_con)\n",
    "training          = pd.read_sql_query(\"SELECT * FROM training;\", staff_con)\n",
    "print(\"Imported staff tables\")\n",
    "\n",
    "crm_con = sqlite3.connect(\"go_crm.sqlite\")\n",
    "crm_tables = pd.read_sql_query(select_tables, crm_con)\n",
    "                           \n",
    "age_group             = pd.read_sql_query(\"SELECT * FROM age_group;\", crm_con)\n",
    "crm_country           = pd.read_sql_query(\"SELECT * FROM country;\", crm_con)\n",
    "retailer              = pd.read_sql_query(\"SELECT * FROM retailer;\", crm_con)\n",
    "retailer_contact      = pd.read_sql_query(\"SELECT * FROM retailer_contact;\", crm_con)\n",
    "retailer_headquarters = pd.read_sql_query(\"SELECT * FROM retailer_headquarters;\", crm_con)\n",
    "retailer_segment      = pd.read_sql_query(\"SELECT * FROM retailer_segment;\", crm_con)\n",
    "crm_retailer_site     = pd.read_sql_query(\"SELECT * FROM retailer_site;\", crm_con)\n",
    "retailer_type         = pd.read_sql_query(\"SELECT * FROM retailer_type;\", crm_con)\n",
    "sales_demographic     = pd.read_sql_query(\"SELECT * FROM sales_demographic;\", crm_con)\n",
    "sales_territory       = pd.read_sql_query(\"SELECT * FROM sales_territory;\", crm_con)\n",
    "print(\"Imported crm tables\")\n",
    "\n",
    "inventory_level = pd.read_csv(\"GO_SALES_INVENTORY_LEVELSData.csv\")\n",
    "print(\"Imported inventory table\")\n",
    "\n",
    "sales_forecast = pd.read_csv(\"GO_SALES_PRODUCT_FORECASTData.csv\")\n",
    "print(\"Imported sales product forecast table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Server connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'test      '), (2, 'test2     ')]\n"
     ]
    }
   ],
   "source": [
    "servername = 'DESKTOP-9F8A8PF\\\\MSSQLSERVER01'\n",
    "database = 'Datawarehouse'\n",
    "\n",
    "sql_server_conn = pyodbc.connect(f\"DRIVER={{SQL Server}};SERVER={servername};DATABASE={database};Trusted_Connection=yes\")\n",
    "cursor = sql_server_conn.cursor()\n",
    "\n",
    "try:\n",
    "    cursor.execute(\"SELECT * FROM Test\")\n",
    "    test = cursor.fetchall()\n",
    "    print(test)\n",
    "except pyodbc.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Flexible method to merge two tables\n",
    "- NaN values of one dataframe can be filled by the other dataframe\n",
    "- Uses all available columns\n",
    "- Errors when a row of the two dataframes doesn't match (df1 has 'A' and df2 has 'B' in row)\n",
    "\"\"\"\n",
    "def merge_tables(df1, df2, index_col):\n",
    "    # Ensure 'CODE' is set as the index for both DataFrames\n",
    "    if index_col not in df1.columns or index_col not in df2.columns:\n",
    "        raise KeyError(f\"{index_col} must be a column in both DataFrames.\")\n",
    "    \n",
    "    df1 = df1.set_index(index_col)\n",
    "    df2 = df2.set_index(index_col)\n",
    "\n",
    "    # Identify common and exclusive columns\n",
    "    common_columns = df1.columns.intersection(df2.columns)\n",
    "    exclusive_df1 = df1.columns.difference(df2.columns)\n",
    "    exclusive_df2 = df2.columns.difference(df1.columns)\n",
    "\n",
    "    # Concatenate exclusive columns from each DataFrame onto the other\n",
    "    df1_combined = pd.concat([df1, df2[exclusive_df2]], axis=1, sort=False)\n",
    "    df2_combined = pd.concat([df2, df1[exclusive_df1]], axis=1, sort=False)\n",
    "\n",
    "    # Resolve common columns with nulls and conflicts\n",
    "    for col in common_columns:\n",
    "        # Align the Series from both DataFrames for comparison\n",
    "        series1, series2 = df1_combined[col].align(df2_combined[col])\n",
    "\n",
    "        # Check for conflicts (non-null values that do not match)\n",
    "        conflict_mask = (~series1.isnull() & ~series2.isnull() & (series1 != series2))\n",
    "        if conflict_mask.any():\n",
    "            raise ValueError(f\"Merge failed due to conflict in column '{col}'\")\n",
    "\n",
    "        # Use values from df2 where df1 is null (prioritizing df1 values)\n",
    "        df1_combined[col] = series1.combine_first(series2)\n",
    "\n",
    "    return df1_combined\n",
    "\n",
    "# Merge duplicate tables into single table\n",
    "retailer_site = merge_tables(sales_retailer_site, crm_retailer_site, 'RETAILER_SITE_CODE')\n",
    "# Column name mismatch\n",
    "sales_country = sales_country.rename(columns={'COUNTRY': 'COUNTRY_EN'})\n",
    "country = merge_tables(sales_country, crm_country, 'COUNTRY_CODE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'NVARCHAR(80)',\n",
       " 'image': 'NVARCHAR(60)',\n",
       " 'id': 'INT',\n",
       " 'description': 'NTEXT',\n",
       " 'money': 'DECIMAL(19,4)',\n",
       " 'percentage': 'DECIMAL(12,12)',\n",
       " 'date': 'NVARCHAR(30)',\n",
       " 'code': 'NVARCHAR(40)',\n",
       " 'char': 'CHAR(1)',\n",
       " 'number': 'INT',\n",
       " 'phone': 'NVARCHAR(30)',\n",
       " 'address': 'NVARCHAR(80)',\n",
       " 'bool': 'BIT'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_mapping = {\n",
    "    'ACTIVE_INDICATOR': 'ACTIVE_INDICATOR_bool',\n",
    "    'ADDRESS1': 'ADDRESS1_address',\n",
    "    'ADDRESS2': 'ADDRESS2_address',\n",
    "    'CITY': 'CITY_name',\n",
    "    'COMPANY_NAME': 'COMPANY_name',\n",
    "    'COUNTRY_CODE': 'COUNTRY_id',\n",
    "    'COUNTRY_EN': 'COUNTRY_name',\n",
    "    'COURSE_CODE': 'COURSE_id',\n",
    "    'COURSE_DESCRIPTION': 'COURSE_description',\n",
    "    'COUNTRY_LANGUAGE_code': 'COUNTRY_LANGUAGE_id',\n",
    "    'CURRENCY_NAME': 'CURRENCY_name',\n",
    "    'DATE_HIRED': 'DATE_HIRED_date',\n",
    "    'DESCRIPTION': 'PRODUCT_description',\n",
    "    'EMAIL': 'EMAIL_address',\n",
    "    'EXPECTED_VOLUME': 'EXPECTED_VOLUME_number',\n",
    "    'EXTENSION': 'EXTENSION_number',\n",
    "    'E_MAIL': 'EMAIL_address',\n",
    "    'FAX': 'FAX_phone',\n",
    "    'FIRST_NAME': 'FIRST_NAME_name',\n",
    "    'FLAG_IMAGE': 'FLAG_image',\n",
    "    'GENDER': 'GENDER_char',\n",
    "    'INTRODUCTION_DATE': 'PRODUCT_INTRODUCTION_DATE_date',\n",
    "    'JOB_POSITION_EN': 'JOB_POSITION_name',\n",
    "    'LANGUAGE': 'LANGUAGE_name',\n",
    "    'LAST_NAME': 'LAST_NAME_name',\n",
    "    'MANAGER_CODE': 'MANAGER_id',\n",
    "    'MARGIN': 'PRODUCT_MARGIN_percentage',\n",
    "    'MONTH': 'MONTH_number',\n",
    "    'ORDER_DATE': 'ORDER_DATE_date',\n",
    "    'ORDER_DETAIL_CODE': 'ORDER_DETAIL_id',\n",
    "    'ORDER_METHOD_CODE': 'ORDER_METHOD_id',\n",
    "    'ORDER_METHOD_EN': 'ORDER_METHOD_name',\n",
    "    'ORDER_NUMBER': 'ORDER_TABLE_id',\n",
    "    'PHONE': 'PHONE_phone',\n",
    "    'POSITION_EN': 'POSITION_name',\n",
    "    'POSTAL_ZONE': 'POSTAL_ZONE_code',\n",
    "    'PRODUCTION_COST': 'PRODUCT_PRODUCTION_COST_money',\n",
    "    'PRODUCT_IMAGE': 'PRODUCT_image',\n",
    "    'PRODUCT_LINE_CODE': 'PRODUCT_LINE_id',\n",
    "    'PRODUCT_LINE_EN': 'PRODUCT_LINE_name',\n",
    "    'PRODUCT_NAME': 'PRODUCT_name',\n",
    "    'PRODUCT_NUMBER': 'PRODUCT_id',\n",
    "    'QUANTITY': 'QUANTITY_number',\n",
    "    'REGION': 'REGION_name',\n",
    "    'RETAILER_CODE': 'RETAILER_id',\n",
    "    'RETAILER_CODEMR': 'RETAILER_MR_id',\n",
    "    'RETAILER_CONTACT_CODE': 'RETAILER_CONTACT_id',\n",
    "    'RETAILER_NAME': 'RETAILER_name',\n",
    "    'RETAILER_SITE_CODE': 'RETAILER_SITE_id',\n",
    "    'RETAILER_TYPE_CODE': 'RETAILER_TYPE_id',\n",
    "    'RETAILER_TYPE_EN': 'RETAILER_TYPE_name',\n",
    "    'RETURN_CODE': 'RETURNS_id',\n",
    "    'RETURN_DATE': 'RETURN_DATE_date',\n",
    "    'RETURN_DESCRIPTION_EN': 'RETURN_REASON_description',\n",
    "    'RETURN_QUANTITY': 'RETURN_QUANTITY_number',\n",
    "    'RETURN_REASON_CODE': 'RETURN_REASON_id',\n",
    "    'SALES_BRANCH_CODE': 'SALES_BRANCH_id',\n",
    "    'SALES_STAFF_CODE': 'SALES_STAFF_id',\n",
    "    'SALES_TERRITORY_CODE': 'SALES_TERRITORY_id',\n",
    "    'SATISFACTION_TYPE_CODE': 'SATISFACTION_TYPE_id',\n",
    "    'SATISFACTION_TYPE_DESCRIPTION': 'SATISFACTION_TYPE_description',\n",
    "    'SEGMENT_CODE': 'SEGMENT_code',\n",
    "    'SEGMENT_LANGUAGE_code': 'SEGMENT_LANGUAGE_id',\n",
    "    'TERRITORY_NAME_EN': 'TERRITORY_name',\n",
    "    'UNIT_COST': 'UNIT_COST_money',\n",
    "    'UNIT_PRICE': 'UNIT_PRICE_money',\n",
    "    'UNIT_SALE_PRICE': 'UNIT_SALE_PRICE_money',\n",
    "    'WORK_PHONE': 'WORK_PHONE_phone',\n",
    "    'YEAR': 'YEAR_number'\n",
    "}\n",
    "\n",
    "# List of all vetted columns\n",
    "valid_columns = list(rename_mapping.values())\n",
    "\n",
    "# Filters out all columns of dataframe that aren't typed\n",
    "def filterColumns(dataframe):\n",
    "    valid_columns_set = set(valid_columns)\n",
    "    actual_columns_set = set(dataframe.columns)\n",
    "    intersection_columns = list(actual_columns_set.intersection(valid_columns_set))\n",
    "\n",
    "    # Use the intersection result to filter columns from dataframe\n",
    "    return dataframe[intersection_columns]\n",
    "\n",
    "# Filters out all columns of dataframe that aren't typed\n",
    "def excludeColumns(dataframe, column_names):\n",
    "    return dataframe[dataframe.columns.difference(column_names)]\n",
    "\n",
    "def sizeCheck(dataframe, expected_column_count):\n",
    "    actual_column_count = len(dataframe.columns)\n",
    "    if actual_column_count == expected_column_count:\n",
    "        print(f'Table has {expected_column_count} columns')\n",
    "    else:\n",
    "        raise Exception(f'Table has {actual_column_count} columns, expected {expected_column_count}')\n",
    "\n",
    "\n",
    "column_types = {\n",
    "    'name': 'NVARCHAR(80)',\n",
    "    'image': 'NVARCHAR(60)',\n",
    "    'id': 'INT',\n",
    "    'description': 'NTEXT',\n",
    "    'money': 'DECIMAL(19,4)',\n",
    "    'percentage': 'DECIMAL(12,12)',\n",
    "    'date': 'NVARCHAR(30)',\n",
    "    'code': 'NVARCHAR(40)',\n",
    "    'char': 'CHAR(1)',\n",
    "    'number': 'INT',\n",
    "    'phone': 'NVARCHAR(30)',\n",
    "    'address': 'NVARCHAR(80)',\n",
    "    'bool': 'BIT',\n",
    "}\n",
    "\n",
    "def getTypes():\n",
    "    types = {}\n",
    "    for column in rename_mapping.values():\n",
    "        column_type = column.rsplit('_', 1)[1]\n",
    "        types[column_type] = ''\n",
    "    return types\n",
    "\n",
    "def columnType(column_name):\n",
    "    err = ''\n",
    "    try:\n",
    "        return column_types[column_name.rsplit('_', 1)[1]]\n",
    "    except IndexError:\n",
    "        err = \"Column name doesn't contain a type\"\n",
    "    except KeyError:\n",
    "        err = \"Column type not found\"\n",
    "    raise Exception(err)\n",
    "\n",
    "def createTable(dataframe, PK):\n",
    "    # Primary key with the type extension removed\n",
    "    # Manual labor isn't worth it!\n",
    "    tablename = PK.rsplit('_', 1)[0]\n",
    "\n",
    "    # Add Primary Key as first column\n",
    "    columns = f'{PK} {columnType(PK)} NOT NULL PRIMARY KEY'\n",
    "\n",
    "    # Add all the other columns\n",
    "    for column in dataframe.columns:\n",
    "        if column != PK: # PK is already added\n",
    "            columns += f', {column} {columnType(column)}'\n",
    "\n",
    "    # Create the command\n",
    "    command = f\"CREATE TABLE {tablename} ({columns})\"\n",
    "\n",
    "    print(command)\n",
    "\n",
    "    try:\n",
    "        cursor.execute(command)\n",
    "        cursor.commit()\n",
    "    except pyodbc.Error as e:\n",
    "        if 'There is already an object named' in str(e):\n",
    "            print('Table already exists in database')\n",
    "        else:\n",
    "            raise(e)\n",
    "\n",
    "\n",
    "column_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 10 columns\n",
      "CREATE TABLE PRODUCT (PRODUCT_id INT NOT NULL PRIMARY KEY, PRODUCT_description NTEXT, PRODUCT_MARGIN_percentage DECIMAL(12,12), PRODUCT_PRODUCTION_COST_money DECIMAL(19,4), PRODUCT_image NVARCHAR(60), PRODUCT_LINE_name NVARCHAR(80), PRODUCT_INTRODUCTION_DATE_date NVARCHAR(30), LANGUAGE_name NVARCHAR(80), PRODUCT_LINE_id INT, PRODUCT_name NVARCHAR(80))\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "product_etl = pd.merge(product, product_type, on=\"PRODUCT_TYPE_CODE\")\n",
    "product_etl = pd.merge(product_etl, product_line, on=\"PRODUCT_LINE_CODE\")\n",
    "\n",
    "# Rename\n",
    "product_etl = product_etl.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "product_etl = filterColumns(product_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(product_etl,10)\n",
    "product_etl\n",
    "\n",
    "# Create\n",
    "createTable(product_etl, 'PRODUCT_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Staff ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 23 columns\n",
      "CREATE TABLE SALES_STAFF (SALES_STAFF_id INT NOT NULL PRIMARY KEY, WORK_PHONE_phone NVARCHAR(30), EMAIL_address NVARCHAR(80), EXTENSION_number INT, LANGUAGE_name NVARCHAR(80), FLAG_image NVARCHAR(60), COUNTRY_id INT, POSITION_name NVARCHAR(80), FAX_phone NVARCHAR(30), REGION_name NVARCHAR(80), MANAGER_id INT, POSTAL_ZONE_code NVARCHAR(40), SALES_BRANCH_id INT, TERRITORY_name NVARCHAR(80), SALES_TERRITORY_id INT, LAST_NAME_name NVARCHAR(80), ADDRESS2_address NVARCHAR(80), DATE_HIRED_date NVARCHAR(30), CURRENCY_name NVARCHAR(80), FIRST_NAME_name NVARCHAR(80), COUNTRY_name NVARCHAR(80), ADDRESS1_address NVARCHAR(80), CITY_name NVARCHAR(80))\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "sales_staff_etl = pd.merge(sales_staff, sales_branch, on='SALES_BRANCH_CODE')\n",
    "sales_staff_etl = pd.merge(sales_staff_etl, country, on='COUNTRY_CODE')\n",
    "sales_staff_etl = pd.merge(sales_staff_etl, sales_territory, on='SALES_TERRITORY_CODE')\n",
    "\n",
    "# Rename\n",
    "sales_staff_etl = sales_staff_etl.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "sales_staff_etl = filterColumns(sales_staff_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(sales_staff_etl,23)\n",
    "sales_staff_etl\n",
    "\n",
    "# Create\n",
    "createTable(sales_staff_etl, 'SALES_STAFF_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satisfaction type ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 2 columns\n",
      "CREATE TABLE SATISFACTION_TYPE (SATISFACTION_TYPE_id INT NOT NULL PRIMARY KEY, SATISFACTION_TYPE_description NTEXT)\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Rename\n",
    "satisfaction_type_etl = satisfaction_type.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "satisfaction_type_etl = filterColumns(satisfaction_type_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(satisfaction_type_etl,2)\n",
    "satisfaction_type_etl\n",
    "\n",
    "# Create\n",
    "createTable(satisfaction_type_etl, 'SATISFACTION_TYPE_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 2 columns\n",
      "CREATE TABLE COURSE (COURSE_id INT NOT NULL PRIMARY KEY, COURSE_description NTEXT)\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Rename\n",
    "course_etl = course.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "course_etl = filterColumns(course_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(course_etl,2)\n",
    "course_etl\n",
    "\n",
    "# Create\n",
    "createTable(course_etl, 'COURSE_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Forecast ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 4 columns\n",
      "CREATE TABLE PRODUCT (PRODUCT_id INT NOT NULL PRIMARY KEY, MONTH_number INT, YEAR_number INT, EXPECTED_VOLUME_number INT)\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Rename\n",
    "sales_forecast_etl = sales_forecast.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "sales_forecast_etl = filterColumns(sales_forecast_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(sales_forecast_etl,4)\n",
    "sales_forecast_etl\n",
    "\n",
    "# Create\n",
    "createTable(sales_forecast_etl, 'PRODUCT_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retailer Contact ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 23 columns\n",
      "CREATE TABLE RETAILER_CONTACT (RETAILER_CONTACT_id INT NOT NULL PRIMARY KEY, JOB_POSITION_name NVARCHAR(80), EMAIL_address NVARCHAR(80), EXTENSION_number INT, LANGUAGE_name NVARCHAR(80), FLAG_image NVARCHAR(60), COUNTRY_id INT, REGION_name NVARCHAR(80), FAX_phone NVARCHAR(30), POSTAL_ZONE_code NVARCHAR(40), RETAILER_SITE_id INT, TERRITORY_name NVARCHAR(80), SALES_TERRITORY_id INT, GENDER_char CHAR(1), LAST_NAME_name NVARCHAR(80), ADDRESS2_address NVARCHAR(80), RETAILER_id INT, CURRENCY_name NVARCHAR(80), ACTIVE_INDICATOR_bool BIT, FIRST_NAME_name NVARCHAR(80), COUNTRY_name NVARCHAR(80), ADDRESS1_address NVARCHAR(80), CITY_name NVARCHAR(80))\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "retailer_contact_etl = pd.merge(retailer_contact, retailer_site, on='RETAILER_SITE_CODE')\n",
    "retailer_contact_etl = pd.merge(retailer_contact_etl, country, on='COUNTRY_CODE')\n",
    "retailer_contact_etl = pd.merge(retailer_contact_etl, sales_territory, on='SALES_TERRITORY_CODE')\\\n",
    "    \n",
    "# Rename \n",
    "retailer_contact_etl = retailer_contact_etl.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "retailer_contact_etl = filterColumns(retailer_contact_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(retailer_contact_etl,23)\n",
    "retailer_contact_etl\n",
    "\n",
    "# Create\n",
    "createTable(retailer_contact_etl, 'RETAILER_CONTACT_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retailer ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 22 columns\n",
      "CREATE TABLE RETAILER (RETAILER_id INT NOT NULL PRIMARY KEY, COUNTRY_LANGUAGE_id INT, FLAG_image NVARCHAR(60), COUNTRY_id INT, REGION_name NVARCHAR(80), FAX_phone NVARCHAR(30), PHONE_phone NVARCHAR(30), POSTAL_ZONE_code NVARCHAR(40), TERRITORY_name NVARCHAR(80), RETAILER_name NVARCHAR(80), SALES_TERRITORY_id INT, SEGMENT_code NVARCHAR(40), SEGMENT_LANGUAGE_id INT, RETAILER_TYPE_id INT, ADDRESS2_address NVARCHAR(80), RETAILER_TYPE_name NVARCHAR(80), CURRENCY_name NVARCHAR(80), COUNTRY_name NVARCHAR(80), RETAILER_MR_id INT, ADDRESS1_address NVARCHAR(80), CITY_name NVARCHAR(80), COMPANY_name NVARCHAR(80))\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "retailer_etl = pd.merge(retailer, retailer_headquarters, on='RETAILER_CODEMR')\n",
    "retailer_etl = pd.merge(retailer_etl, retailer_type, on='RETAILER_TYPE_CODE')\n",
    "\n",
    "# Merge and rename language columns for clarity\n",
    "retailer_etl = pd.merge(retailer_etl, retailer_segment, on='SEGMENT_CODE').rename(columns={'LANGUAGE':'SEGMENT_LANGUAGE_code'})\n",
    "retailer_etl = pd.merge(retailer_etl, country, on='COUNTRY_CODE').rename(columns={'LANGUAGE':'COUNTRY_LANGUAGE_code'})\n",
    "\n",
    "# Exclude columns early due to merge naming conflicts\n",
    "retailer_etl = excludeColumns(retailer_etl, ['TRIAL219','TRIAL222_x','TRIAL222_y','TRIAL222'])\n",
    "\n",
    "# Rename\n",
    "retailer_etl = pd.merge(retailer_etl, sales_territory, on='SALES_TERRITORY_CODE')\\\n",
    "    .rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "retailer_etl = filterColumns(retailer_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(retailer_etl,22)\n",
    "retailer_etl\n",
    "\n",
    "# Create\n",
    "createTable(retailer_etl, 'RETAILER_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 7 columns\n",
      "CREATE TABLE ORDER_TABLE (ORDER_TABLE_id INT NOT NULL PRIMARY KEY, RETAILER_name NVARCHAR(80), RETAILER_CONTACT_id INT, ORDER_METHOD_name NVARCHAR(80), ORDER_METHOD_id INT, ORDER_DATE_date NVARCHAR(30), SALES_STAFF_id INT)\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "order_etl = pd.merge(order_header, order_method, on='ORDER_METHOD_CODE').rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude redundant foreign key columns\n",
    "# RETAILER_SITE_code can be derived from RETAILER_CONTACT_id\n",
    "# SALES_BRANCH_code can be derived from SALES_STAFF_id\n",
    "order_etl = excludeColumns(order_etl, ['RETAILER_SITE_id', 'SALES_BRANCH_id'])\n",
    "\n",
    "# Exclude\n",
    "order_etl = filterColumns(order_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(order_etl,7)\n",
    "order_etl\n",
    "\n",
    "# Create\n",
    "createTable(order_etl, 'ORDER_TABLE_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return reason ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 2 columns\n",
      "CREATE TABLE RETURN_REASON (RETURN_REASON_id INT NOT NULL PRIMARY KEY, RETURN_REASON_description NTEXT)\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Rename\n",
    "return_reason_etl = return_reason.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "return_reason_etl = filterColumns(return_reason_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(return_reason_etl,2)\n",
    "return_reason_etl\n",
    "\n",
    "# Create\n",
    "createTable(return_reason_etl, 'RETURN_REASON_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returned Item ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 5 columns\n",
      "CREATE TABLE RETURNS (RETURNS_id INT NOT NULL PRIMARY KEY, RETURN_QUANTITY_number INT, RETURN_DATE_date NVARCHAR(30), ORDER_DETAIL_id INT, RETURN_REASON_id INT)\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Rename \n",
    "returned_item_etl = returned_item.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude \n",
    "returned_item_etl = filterColumns(returned_item_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(returned_item_etl,5)\n",
    "returned_item_etl\n",
    "\n",
    "# Create\n",
    "createTable(returned_item_etl, 'RETURNS_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Details ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has 7 columns\n",
      "CREATE TABLE ORDER_DETAIL (ORDER_DETAIL_id INT NOT NULL PRIMARY KEY, UNIT_PRICE_money DECIMAL(19,4), QUANTITY_number INT, UNIT_COST_money DECIMAL(19,4), PRODUCT_id INT, ORDER_TABLE_id INT, UNIT_SALE_PRICE_money DECIMAL(19,4))\n",
      "Table already exists in database\n"
     ]
    }
   ],
   "source": [
    "# Rename\n",
    "order_detail_etl = order_details.rename(columns=rename_mapping)\n",
    "\n",
    "# Exclude\n",
    "order_detail_etl = filterColumns(order_detail_etl)\n",
    "\n",
    "# Assert\n",
    "sizeCheck(order_detail_etl,7)\n",
    "order_detail_etl\n",
    "\n",
    "# Create\n",
    "createTable(order_detail_etl, 'ORDER_DETAIL_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr4-3-gQyTh7EJ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
